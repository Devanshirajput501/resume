Data Engineering:
- 


Algorithm:
- Linear Regression
- Random Forest 
- Factor Analysis
- Logistic regression
- 



Tools:
- 






Other:
- ESG (Environmental, Social, & Governance)
- Graph Modelling
- Models that can utilize Number and Text as Inputs 
- Combining various models

+ Build/integrate business intelligence and analytics tools that utilise available data pipelines to provide actionable insights for the business, our customers and other stakeholders
+ Work with the organisation's data analysts, application support and DevOps to assist with data-related technical issues and analyses
+ Implement processes and systems to monitor data quality
+ Identify, design and implement internal process improvements
+ Create and maintain analytical tooling as data volume and complexity increases.



+ Familiarity with at least one business intelligence tool (e.g. Tableau, Google Data Studio, Microsoft BI, etc. ) including data visualisation using such tools.
+ Demonstrable experience with at least one statistical programming language (Python, R or similar)
+ Knowledge of data structures and experience of working with large datasets within an enterprise context
+ Demonstrable experience of articulating and translating business questions and using statistical techniques to arrive at an answer using available data
+ Demonstrable experience with or knowledge of Agile software development methodologies.






Profiles
Blog
Dribble
about.me
Website





KRA - Key Responsibility Areas
KPI - Key Performance Indicator




Responsibilities

Superior analytical and problem-solving skills
High Proficiency in Python Coding along with good knowledge of SQL
Knowledge of using Python Libraries such as scikit-learn, scipy, pandas, numpy , nltk, matplotlib
Deep rooted knowledge and understanding Traditional Machine Learning Algorithms & Advanced modelling techniques (e.g. Random Forest, SVM, time series etc.) and Text Analytics technique (NLTK, Genism, LDA etc.)
Must have hands on experience of building and deploying Predictive Models



5+ Years of strong development experience building robust Data ingestion and processing pipelines using tools like Apache NiFi, Python programming as well as Autosys
Strong Skills in Relational Databases including database design, modeling, SQL and stored procedures
Experience with Big Data processing and technologies like Snowflake, Databricks, Hadoop, Spark, Kafka
Experience and expertise working with data wrangling and visualization tools like Dataiku, Tableau, Power BI
Experience working on UNIX/Linux platform, Shell scripting
Experience with full SDLC process and Agile Methodologies
Experience with TDD, BDD methodologies and frameworks
Experience in managing deployments and build frameworks
Strong problem-solving skills, business acumen, and demonstrated excellent oral and written communication skills with both technical and non-technical audiences




SDLC & Database
DS & Algorithms - string, queues, and stacks
System Design - LLD and HLD
Scale : https://scale.com/
API Testing (Manual and Automation)
Automation Framework Design
AWS /GCP / Azure or other cloud platforms
Deployment, Maintenance, Bug fixes, L2 activities, DevOps
distributed systems / large scale applications 

Familiarity with data science/ML packages, tools and languages (R, Scikit-Learn, MATLAB/Octave, Julia, WEKA)
Familiarity with NLP toolkits (Stanford CoreNLP, NLTK, ClearTK)
Exposure to NLP annotation models, such as dependency grammars (Universal Dependencies), Penn Treebank, etc.
Hands on experience in SQL, spring and crownsourced platforms is a plus.



A Detail oriented and data-driven person with a wide range of experience in working with multiple v's of data and producing great results tailored to meet the need in the available business constraints.





Credentialing Healthcare
